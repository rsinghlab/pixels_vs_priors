{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdfab23-ac67-4af9-afef-035372b4ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "df = pd.read_csv(\"final_images.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3bc217-510e-41aa-9cea-2d8b1b0d977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_average_size(object_name, model_version=\"gpt-4o\"):\n",
    "    API_KEY = \"YOUR API KEY HERE\"\n",
    "    client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "    prompt = f\"What is the average size of a {object_name}? Give your final answer in the format number_length feet x number_width feet. So for example, final answer: 3.7 feet x 10.13 feet.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_version,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Provide average size in feet for a given object.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        top_p=1\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Loop through dataframe and get average size\n",
    "sizes = []\n",
    "for obj in df[\"correct_object\"]:\n",
    "    avg_size = get_average_size(obj)\n",
    "    sizes.append(avg_size)\n",
    "\n",
    "df[\"average_size\"] = sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82daa7f1-7af3-4637-a813-d4be28c89d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"average_size\"] = df[\"average_size\"].str.replace(\"foot\", \"feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f80dfd-a144-4f71-8d29-cc4a311d51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"average_size\"] = df[\"average_size\"].str.replace(\"N/A\", \"0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27372b20-d4dc-4474-83b8-159a01ed61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_most_precise_measurements(text):\n",
    "    \"\"\"\n",
    "    Extracts the most precise 'feet x feet' format measurement from a given text.\n",
    "    Prioritizes values that explicitly follow 'approximately' or are in the final stated dimensions.\n",
    "    \"\"\"\n",
    "    # Look for 'approximately X feet x Y feet' explicitly\n",
    "    pattern = r'approximately\\s+(\\d*\\.?\\d+)\\s*feet.*?\\bx\\b.*?(\\d*\\.?\\d+)\\s*feet'\n",
    "    \n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"{match.group(1)} feet x {match.group(2)} feet\"\n",
    "\n",
    "    # Fallback: If 'approximately' is not present, try generic extraction\n",
    "    fallback_pattern = r'(\\d*\\.?\\d+)\\s*feet\\s*\\(?.*?\\)?\\s*x\\s*(\\d*\\.?\\d+)\\s*feet'\n",
    "    fallback_match = re.findall(fallback_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    if fallback_match:\n",
    "        return f\"{fallback_match[-1][0]} feet x {fallback_match[-1][1]} feet\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df[\"extracted_size\"] = df[\"average_size\"].apply(extract_most_precise_measurements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed9031-f170-4a71-a075-7e7b7e740d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_size(extracted_size):\n",
    "    \"\"\"\n",
    "    Calculates the total size by multiplying the two extracted dimensions in feet.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract numerical values from the 'feet x feet' format\n",
    "        dimensions = re.findall(r'(\\d*\\.?\\d+)', extracted_size)\n",
    "        if len(dimensions) == 2:\n",
    "            width, height = map(float, dimensions)\n",
    "            return width * height  # Compute total size as area in square feet\n",
    "    except:\n",
    "        return None  # Return None if extraction fails\n",
    "\n",
    "# Apply the function to create the \"total_size\" column\n",
    "df[\"total_size\"] = df[\"extracted_size\"].apply(calculate_total_size)\n",
    "df[\"total_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4b7af-ad96-41fe-8c9e-9da81ef91c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"total_size\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb8bdd-f6f6-415b-99ad-05ac1750acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_images_extracted_sizes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614e985-e02f-4c7f-b8ab-25b9006cbaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b2082-8477-46c9-8d58-59da4a7c2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_objects = [\n",
    "    \"American egret\",\n",
    "    \"cottage\",\n",
    "    \"hotdog\",\n",
    "    \"swab\",\n",
    "    \"radio telescope\",\n",
    "    \"cab\",\n",
    "    \"carbonara\",\n",
    "    \"three-toed sloth\",\n",
    "    \"computer keyboard\",\n",
    "    \"cupboard\",\n",
    "    \"theater curtain\",\n",
    "    \"dugong\",\n",
    "    \"electric fan\",\n",
    "    \"indigo bunting\",\n",
    "    \"solar dish\",\n",
    "    \"komondor\",\n",
    "    \"limpkin\",\n",
    "    \"mashed potato\",\n",
    "    \"mortar\",\n",
    "    \"padlock\",\n",
    "    \"strainer\",\n",
    "    \"rotisserie\",\n",
    "    \"white stork\",\n",
    "    \"yacht\",\n",
    "    \"machete\"\n",
    "]\n",
    "df = df[~df[\"correct_object\"].isin(excluded_objects)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c054fd9-8312-47bf-a9d1-77c182da9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_closest_match(df, target_size, factor, exclude_object):\n",
    "    \"\"\"\n",
    "    Finds the closest valid object in df with a total_size at least `factor` times larger/smaller, \n",
    "    excluding the given object.\n",
    "    \"\"\"\n",
    "    df_filtered = df[df[\"correct_object\"] != exclude_object].copy()  # Exclude itself\n",
    "    df_filtered[\"size_ratio\"] = df_filtered[\"total_size\"] / target_size\n",
    "\n",
    "    # Expand valid range (5x to 500x instead of a strict 100x)\n",
    "    if factor > 1:  # Looking for a larger object\n",
    "        df_filtered = df_filtered[df_filtered[\"size_ratio\"] >= 10]  # Ensure at least 5x larger\n",
    "    else:  # Looking for a smaller object\n",
    "        df_filtered = df_filtered[df_filtered[\"size_ratio\"] <= 0.1]  # Ensure at least 5x smaller\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        return None, None\n",
    "\n",
    "    # Select the closest match by absolute size ratio difference\n",
    "    closest_match = df_filtered.iloc[(df_filtered[\"size_ratio\"] - factor).abs().argsort()[:1]]\n",
    "    return closest_match[\"correct_object\"].values[0], closest_match[\"total_size\"].values[0]\n",
    "\n",
    "# Create new dataframe for object pairings with proper exclusions and valid scaling\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    obj_name = row[\"correct_object\"]\n",
    "    obj_size = row[\"total_size\"]\n",
    "\n",
    "    # Find a larger object (5x-500x bigger), ensuring a valid match or None\n",
    "    larger_obj, larger_size = find_closest_match(df, obj_size, 200, obj_name)\n",
    "\n",
    "    # Find a smaller object (5x-500x smaller), ensuring a valid match or None\n",
    "    smaller_obj, smaller_size = find_closest_match(df, obj_size, 1/200, obj_name)\n",
    "\n",
    "    expanded_rows.append([obj_name, obj_size, larger_obj, larger_size, smaller_obj, smaller_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb61578-6902-460d-a40c-14ffac1f5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairings_final = pd.DataFrame(expanded_rows, columns=[\"correct_object\", \"total_size\", \"larger_object\", \"larger_size\", \"smaller_object\", \"smaller_size\"])\n",
    "\n",
    "df_combined = df.merge(df_pairings_final, on=[\"correct_object\", \"total_size\"], how=\"left\")\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4e09d-1df2-4c00-acf1-abdf2f7f6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_combined.iterrows():\n",
    "    obj = row[\"correct_object\"]\n",
    "    larger = row[\"larger_object\"]\n",
    "    smaller = row[\"smaller_object\"]\n",
    "\n",
    "    if larger not in df_combined[\"correct_object\"].values:\n",
    "        print(f\"[{obj}] Missing larger_object: {larger}\")\n",
    "    \n",
    "    if smaller not in df_combined[\"correct_object\"].values:\n",
    "        print(f\"[{obj}] Missing smaller_object: {smaller}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eacd98-9e71-4bd5-bb39-d7d404016be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"images_extracted_sizes_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fbab4-c75e-4a3e-be24-169d257306a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b6e74-8192-46e3-9d40-245b89cd5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Define the file paths for MASKS\n",
    "color_path = \"final_real_images_masks_color.pkl\"\n",
    "white_path = \"final_real_images_masks_white.pkl\"\n",
    "\n",
    "# Load both dictionaries\n",
    "with open(color_path, \"rb\") as f:\n",
    "    color_data = pickle.load(f)\n",
    "\n",
    "with open(white_path, \"rb\") as f:\n",
    "    white_data = pickle.load(f)\n",
    "\n",
    "# Combine the dictionaries\n",
    "combined_data = {}\n",
    "\n",
    "# Combine logic\n",
    "for key in set(color_data.keys()).union(white_data.keys()):\n",
    "    mask_color = color_data.get(key)\n",
    "    mask_white = white_data.get(key)\n",
    "\n",
    "    if mask_color is not None and mask_white is not None:\n",
    "        # Example: combine masks with logical OR\n",
    "        combined_data[key] = np.logical_or(mask_color, mask_white).astype(np.float32)\n",
    "    elif mask_color is not None:\n",
    "        combined_data[key] = mask_color\n",
    "    else:\n",
    "        combined_data[key] = mask_white\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5b7f8-f7ab-4e56-94af-202e3100f1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15573f1-72fb-4ff6-887d-ce7f6db273b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ab4fd-82d7-48bf-9801-47d229c92747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mask_df = pd.DataFrame(list(combined_data.items()), columns=[\"corrupt_image_path\", \"mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083fbb44-b909-4c23-8d0e-0b476ec5bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfact_path(row):\n",
    "    color_to_replace = row['image_path'].split('_')[1]\n",
    "    new_path = row['image_path'].replace(color_to_replace, row['incorrect_answer'])\n",
    "    new_path = new_path.replace('downloaded_images', 'downloaded_images_counterfact')\n",
    "    return new_path\n",
    "\n",
    "df[\"corrupt_image_path\"] = df.apply(generate_counterfact_path, axis=1)\n",
    "df[\"corrupt_image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed8f9b-8c2b-439a-b04f-6af3a7b1055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(mask_df, on=\"corrupt_image_path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da2ea1-bb04-40fa-bb9f-3b003ec337db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import random\n",
    "import os\n",
    "\n",
    "composite_dir = \"composites\"\n",
    "os.makedirs(composite_dir, exist_ok=True)\n",
    "\n",
    "def generate_all_composite_images(df):\n",
    "    skipped_objects = [] \n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"\\nProcessing {row['correct_object']}...\")\n",
    "\n",
    "        obj1 = row[\"correct_object\"]\n",
    "        obj2 = row[\"smaller_object\"]\n",
    "        obj3 = row[\"larger_object\"]\n",
    "\n",
    "        obj1_mask = row[\"mask\"]\n",
    "        obj2_row = df[df[\"correct_object\"] == obj2]\n",
    "        obj3_row = df[df[\"correct_object\"] == obj3]\n",
    "        #\"\"\"\n",
    "        if (\n",
    "            not isinstance(obj1_mask, np.ndarray) or\n",
    "            obj2_row.empty or not isinstance(obj2_row.iloc[0][\"mask\"], np.ndarray) or\n",
    "            obj3_row.empty or not isinstance(obj3_row.iloc[0][\"mask\"], np.ndarray)\n",
    "        ):\n",
    "            print(f\"Skipping {obj1} due to missing or invalid mask data.\")\n",
    "            skipped_objects.append(obj1)\n",
    "            continue\n",
    "        #\"\"\"\n",
    "        obj2_mask = obj2_row.iloc[0][\"mask\"]\n",
    "        obj3_mask = obj3_row.iloc[0][\"mask\"]\n",
    "\n",
    "        obj1_mask = Image.fromarray((obj1_mask * 255).astype(np.uint8))\n",
    "        obj2_mask = Image.fromarray((obj2_mask * 255).astype(np.uint8))\n",
    "        obj3_mask = Image.fromarray((obj3_mask * 255).astype(np.uint8))\n",
    "\n",
    "        obj1_size = row[\"total_size\"]\n",
    "        obj2_size = row[\"smaller_size\"]\n",
    "        obj3_size = row[\"larger_size\"]\n",
    "\n",
    "        def make_case(mask1, mask2, size1, size2, name1, name2, force_larger_is_first=False):\n",
    "            if force_larger_is_first:\n",
    "                size1, size2 = max(size1, size2), min(size1, size2)\n",
    "\n",
    "            if random.choice([True, False]):\n",
    "                left_mask, right_mask = mask1, mask2\n",
    "                left_size, right_size = size1, size2\n",
    "                left_name, right_name = name1, name2\n",
    "            else:\n",
    "                left_mask, right_mask = mask2, mask1\n",
    "                left_size, right_size = size2, size1\n",
    "                left_name, right_name = name2, name1\n",
    "\n",
    "            description = f\"{name1} (larger) vs {name2} (smaller)\"\n",
    "            return (left_mask, right_mask, left_size, right_size, description, left_name, right_name)\n",
    "\n",
    "        def crop_to_mask(mask):\n",
    "            arr = np.array(mask)\n",
    "            rows = np.any(arr > 0, axis=1)\n",
    "            cols = np.any(arr > 0, axis=0)\n",
    "            if not rows.any() or not cols.any():\n",
    "                return mask, (0, 0, mask.width, mask.height)\n",
    "            y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "            x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "            return mask.crop((x_min, y_min, x_max + 1, y_max + 1)), (x_min, y_min, x_max + 1, y_max + 1)\n",
    "\n",
    "        def get_real_image(name):\n",
    "            row_match = df[df[\"correct_object\"] == name]\n",
    "            if not row_match.empty:\n",
    "                return Image.open(row_match.iloc[0][\"image_path\"]).convert(\"RGB\")\n",
    "            return None\n",
    "\n",
    "        cases = [\n",
    "            make_case(obj1_mask, obj2_mask, obj1_size, obj2_size, obj1, obj2),\n",
    "            make_case(obj2_mask, obj1_mask, obj2_size, obj1_size, obj2, obj1, force_larger_is_first=True),\n",
    "            make_case(obj3_mask, obj1_mask, obj3_size, obj1_size, obj3, obj1),\n",
    "            make_case(obj1_mask, obj3_mask, obj1_size, obj3_size, obj1, obj3, force_larger_is_first=True),\n",
    "        ]\n",
    "\n",
    "        for left_mask, right_mask, left_size, right_size, description, left_name, right_name in cases:\n",
    "            print(f\"\\nGenerating: {description}\")\n",
    "\n",
    "            LARGER_DIM = (250, 250)\n",
    "            SMALLER_DIM = (80, 80)\n",
    "\n",
    "            larger_label = description.split(\"vs\")[0].strip()\n",
    "            left_is_larger = left_name in larger_label\n",
    "\n",
    "            left_dim = LARGER_DIM if left_is_larger else SMALLER_DIM\n",
    "            right_dim = SMALLER_DIM if left_is_larger else LARGER_DIM\n",
    "\n",
    "            # Crop masks and get crop boxes\n",
    "            left_cropped_mask, left_crop_box = crop_to_mask(left_mask)\n",
    "            right_cropped_mask, right_crop_box = crop_to_mask(right_mask)\n",
    "\n",
    "            # Resize masks\n",
    "            left_resized_mask = left_cropped_mask.resize(left_dim, Image.LANCZOS)\n",
    "            right_resized_mask = right_cropped_mask.resize(right_dim, Image.LANCZOS)\n",
    "\n",
    "            # Prepare canvas\n",
    "            spacing = 20\n",
    "            canvas_width = left_resized_mask.width + right_resized_mask.width + spacing\n",
    "            canvas_height = max(left_resized_mask.height, right_resized_mask.height) + 50\n",
    "\n",
    "            line_y = canvas_height - 50\n",
    "\n",
    "            def find_mask_bottom(mask_img):\n",
    "                mask_arr = np.array(mask_img.convert(\"L\"))\n",
    "                rows = np.where(mask_arr > 0)[0]\n",
    "                return rows.max() if len(rows) > 0 else mask_img.height - 1\n",
    "\n",
    "            left_bottom = find_mask_bottom(left_resized_mask)\n",
    "            right_bottom = find_mask_bottom(right_resized_mask)\n",
    "\n",
    "            left_x = 0\n",
    "            left_y = line_y - left_bottom\n",
    "            right_x = left_resized_mask.width + spacing\n",
    "            right_y = line_y - right_bottom\n",
    "\n",
    "            # --- MASK CANVAS ---\n",
    "            mask_canvas = Image.new(\"RGB\", (canvas_width, canvas_height), \"white\")\n",
    "            draw = ImageDraw.Draw(mask_canvas)\n",
    "            for x in range(0, canvas_width, 20):\n",
    "                draw.line([(x, line_y), (x + 10, line_y)], fill=\"black\", width=2)\n",
    "\n",
    "            mask_canvas.paste(left_resized_mask.convert(\"RGB\"), (left_x, left_y))\n",
    "            mask_canvas.paste(right_resized_mask.convert(\"RGB\"), (right_x, right_y))\n",
    "            display(mask_canvas)\n",
    "\n",
    "            # --- REAL IMAGE CANVAS ---\n",
    "            print(\"Showing real images...\")\n",
    "\n",
    "            def get_real_image(name):\n",
    "                row_match = df[df[\"correct_object\"] == name]\n",
    "                if not row_match.empty:\n",
    "                    return Image.open(row_match.iloc[0][\"image_path\"]).convert(\"RGB\")\n",
    "                return None\n",
    "\n",
    "            left_real = get_real_image(left_name)\n",
    "            right_real = get_real_image(right_name)\n",
    "            \n",
    "            original_left_mask = left_mask  # before cropping\n",
    "            original_right_mask = right_mask\n",
    "            \n",
    "            if left_real:\n",
    "                if left_real.size != original_left_mask.size:\n",
    "                    left_real = left_real.resize(original_left_mask.size, Image.LANCZOS)\n",
    "                left_real_cropped = left_real.crop(left_crop_box)\n",
    "                left_real_resized = left_real_cropped.resize(left_resized_mask.size, Image.LANCZOS)\n",
    "                left_composite = Image.composite(left_real_resized, Image.new(\"RGB\", left_real_resized.size, \"white\"), left_resized_mask.convert(\"L\"))\n",
    "            else:\n",
    "                left_composite = Image.new(\"RGB\", left_resized_mask.size, \"gray\")\n",
    "            \n",
    "            if right_real:\n",
    "                if right_real.size != original_right_mask.size:\n",
    "                    right_real = right_real.resize(original_right_mask.size, Image.LANCZOS)\n",
    "                right_real_cropped = right_real.crop(right_crop_box)\n",
    "                right_real_resized = right_real_cropped.resize(right_resized_mask.size, Image.LANCZOS)\n",
    "                right_composite = Image.composite(right_real_resized, Image.new(\"RGB\", right_real_resized.size, \"white\"), right_resized_mask.convert(\"L\"))\n",
    "            else:\n",
    "                right_composite = Image.new(\"RGB\", right_resized_mask.size, \"gray\")\n",
    "\n",
    "            real_canvas = Image.new(\"RGB\", (canvas_width, canvas_height), \"white\")\n",
    "            real_canvas.paste(left_composite, (left_x, left_y))\n",
    "            real_canvas.paste(right_composite, (right_x, right_y))\n",
    "            draw = ImageDraw.Draw(real_canvas)\n",
    "            for x in range(0, canvas_width, 20):\n",
    "                draw.line([(x, line_y), (x + 10, line_y)], fill=\"black\", width=2)\n",
    "            display(real_canvas)\n",
    "\n",
    "            larger_obj = left_name if left_size > right_size else right_name\n",
    "            smaller_obj = right_name if left_size > right_size else left_name\n",
    "            \n",
    "            # Clean filename\n",
    "            filename = f\"{larger_obj}_larger_than_{smaller_obj}\".replace(\" \", \"_\") + \"_with_line.png\"\n",
    "            save_path = os.path.join(composite_dir, filename)\n",
    "            \n",
    "            # Save real image composite\n",
    "            real_canvas.save(save_path)\n",
    "            print(f\"Saved to: {save_path}\")\n",
    "    return skipped_objects\n",
    "\n",
    "skipped_objects = generate_all_composite_images(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b8f6c-33a5-409f-8b78-f458be8f5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446814b-eb5b-48c0-ae5b-775e1a49c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df[~df[\"correct_object\"].isin(skipped_objects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0ce4a-2544-425f-a8ac-5ed6cd47638d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d5ae6-5c27-4e86-b1ba-4e103092d2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the new rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through the existing dataframe\n",
    "for _, row in df.iterrows():\n",
    "    correct_object = row[\"correct_object\"]\n",
    "    smaller_object = row[\"smaller_object\"]\n",
    "    larger_object = row[\"larger_object\"]\n",
    "\n",
    "    # Generate expected paths for the composite images\n",
    "    path_to_clean_1 = f\"composites/{correct_object}_larger_than_{smaller_object}_with_line.png\"\n",
    "    path_to_counterfact_1 = f\"composites/{smaller_object}_larger_than_{correct_object}_with_line.png\"\n",
    "    path_to_clean_2 = f\"composites/{larger_object}_larger_than_{correct_object}_with_line.png\"\n",
    "    path_to_counterfact_2 = f\"composites/{correct_object}_larger_than_{larger_object}_with_line.png\"\n",
    "\n",
    "    # First row: correct_object vs. smaller_object\n",
    "    new_rows.append({\n",
    "        \"correct_object\": correct_object,\n",
    "        \"comparison_object\": smaller_object,\n",
    "        \"total_size\": row[\"total_size\"],\n",
    "        \"comparison_size\": row[\"smaller_size\"],\n",
    "        #\"attribute\": row[\"attribute\"],\n",
    "        \"correct_answer\": row[\"correct_answer\"],\n",
    "        \"path_to_clean\": path_to_clean_1,\n",
    "        \"path_to_counterfact\": path_to_counterfact_1,\n",
    "    })\n",
    "\n",
    "    # Second row: correct_object vs. larger_object\n",
    "    new_rows.append({\n",
    "        \"correct_object\": correct_object,\n",
    "        \"comparison_object\": larger_object,\n",
    "        \"total_size\": row[\"total_size\"],\n",
    "        \"comparison_size\": row[\"larger_size\"],\n",
    "        #\"attribute\": row[\"attribute\"],\n",
    "        \"correct_answer\": row[\"correct_answer\"],\n",
    "        \"path_to_clean\": path_to_clean_2,\n",
    "        \"path_to_counterfact\": path_to_counterfact_2,\n",
    "    })\n",
    "\n",
    "# Convert to a new DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77e3fb-cdb9-4469-8049-586fae7266d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df[\"correct_object\"] != \"toilet\"]\n",
    "new_df = new_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a21229-fffe-4977-a903-610c38e77632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for clean_answer and counterfact_answer based on size comparison\n",
    "new_df[\"clean_answer\"] = new_df.apply(\n",
    "    lambda row: row[\"correct_object\"] if row[\"total_size\"] > row[\"comparison_size\"] else row[\"comparison_object\"], axis=1\n",
    ")\n",
    "\n",
    "new_df[\"counterfact_answer\"] = new_df.apply(\n",
    "    lambda row: row[\"comparison_object\"] if row[\"total_size\"] > row[\"comparison_size\"] else row[\"correct_object\"], axis=1\n",
    ")\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555c195-3ee9-444d-b504-9d872d67254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates(subset=[\"clean_answer\", \"counterfact_answer\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768563a9-89f6-4eb9-a5dd-0d5723e8444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "for _, row in new_df.iterrows():\n",
    "    clean_img = Image.open(row[\"path_to_clean\"])#.convert(\"RGB\")\n",
    "    counterfact_img = Image.open(row[\"path_to_counterfact\"])#.convert(\"RGB\")\n",
    "\n",
    "    print(\"Clean Image:\")\n",
    "    display(clean_img)\n",
    "\n",
    "    print(\"Counterfactual Image:\")\n",
    "    display(counterfact_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0f779-c9ec-43c2-b0d9-0c254414bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"images_composite_images_with_line.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
