{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98293656-ff59-443a-a0e5-50b6a0779d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import requests\n",
    "\n",
    "#Get CIFAR 100 labels:\n",
    "\n",
    "ds = load_dataset(\"uoft-cs/cifar100\")\n",
    "\n",
    "label_names = ds[\"train\"].features[\"fine_label\"].names\n",
    "\n",
    "#Get ImageNet labels:\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "labels = requests.get(url).text.strip().split(\"\\n\")\n",
    "\n",
    "objects = set(labels).union(set(label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be7d91-0c10-473c-bac4-ee30c2cb6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#This is the path to the McRae dataset\n",
    "\n",
    "df = pd.read_csv(\"CONCS_FEATS_concstats_brm.txt\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101c6f7-4018-4c1f-ad21-588cbbf2d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_typical_color(object_name, model_version=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Queries GPT to find the typical color of an object.\n",
    "    If there's no single typical color, GPT should return 'multiple'.\n",
    "    \"\"\"\n",
    "    API_KEY = \"YOUR API KEY HERE\"\n",
    "\n",
    "    client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "    prompt = (\n",
    "        f\"What is the most common color of a '{object_name}'? \"\n",
    "        f\"If there is most common color (clothing for example), just reply with 'multiple'. \"\n",
    "        f\"Give only one-word answer.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_version,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're a visual and color expert.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=10,\n",
    "        temperature=0,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273fe23-7b81-402f-ae06-5eadf755b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "concepts = df[\"Concept\"].unique()\n",
    "color_results = {}\n",
    "\n",
    "for concept in concepts:\n",
    "    color = get_typical_color(concept)\n",
    "    color_results[concept] = color\n",
    "\n",
    "# Optional: convert to DataFrame\n",
    "color_df = pd.DataFrame(list(color_results.items()), columns=[\"Concept\", \"Typical_Color\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a430bce-a8ef-4b8f-a6ff-50f4dd5242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_df[\"Typical_Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9d6b7-4f35-4106-9f32-948796969d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_df = color_df[color_df[\"Typical_Color\"].str.replace(\".\", \"\") != \"multiple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd885e-0803-46b1-9e06-56ca55e9108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_df[\"Concept\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4ec9a-7b7e-427d-ab17-cc32cf073db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique objects! \n",
    "objects = objects - set(color_df[\"Concept\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76096c-f631-4420-b3f9-8cfd270bd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad843ca5-2f28-416e-be32-8b9022f51722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "concepts = list(objects)\n",
    "color_results = {}\n",
    "\n",
    "for concept in concepts:\n",
    "    color = get_typical_color(concept)\n",
    "    print(color)\n",
    "    color_results[concept] = color\n",
    "\n",
    "# Optional: convert to DataFrame\n",
    "color_df2 = pd.DataFrame(list(color_results.items()), columns=[\"Concept\", \"Typical_Color\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c026ac0-b1b8-4c1e-a6d0-e365d85c0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([color_df, color_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff20c48-4733-4b3c-98bd-f90d461351d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Typical_Color\"].str.replace(\".\", \"\") != \"multiple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27446c16-3ec1-4b1a-b699-20af2d7e1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Typical_Color\"] = df[\"Typical_Color\"].str.replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6d9b7-5f49-4e63-88ca-a2e58dcbdeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Typical_Color\"] = df[\"Typical_Color\"].str.replace(\"gray\", \"grey\").str.replace(\"golden\", \"gold\").str.replace(\"olive\", \"green\").str.replace(\"reddish\", \"red\").str.replace(\"yellowish\", \"yellow\").str.replace(\"chestnut\", \"brown\").str.replace(\"beige\", \"tan\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf2ca8-bed4-40a9-b133-44bd1526861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Typical_Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125ac74-bffb-4087-b570-e7c51328e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_colors = [\n",
    "    \"white\", \"black\", \"brown\", \"green\", \"grey\", \"red\", \"silver\", \"yellow\",\n",
    "    \"orange\", \"blue\", \"pink\", \"gold\", \"brass\", \n",
    "    \"tan\",  \"burgundy\", \"purple\"\n",
    "]\n",
    "\n",
    "df = df[df[\"Typical_Color\"].isin(valid_colors)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12bb07-52d0-4242-b92b-35208b8011ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131944e2-6b1e-4acc-8de5-a5ac15954c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Replace these with your actual credentials\n",
    "API_KEY = \"YOUR GOOGLE API KEY\"  # Replace with your API Key\n",
    "CX_ID = \"YOUR GOOGLE CX ID\"  # Your CX ID from the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4193a46-85c7-4cc5-a1b0-61ab8dcfab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a folder to store downloaded images\n",
    "os.makedirs(\"downloaded_images\", exist_ok=True)\n",
    "\n",
    "# Function to fetch and download images\n",
    "def fetch_and_download_images(object_name, color, num_results=3):\n",
    "    QUERY = f\"a {color} {object_name} on a white background\"\n",
    "    URL = f\"https://www.googleapis.com/customsearch/v1?q={QUERY}&cx={CX_ID}&key={API_KEY}&searchType=image&num={num_results}\"\n",
    "\n",
    "    image_urls = []\n",
    "    image_paths = []\n",
    "\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"items\" in data:\n",
    "            image_urls = [item[\"link\"] for item in data[\"items\"][:num_results]]\n",
    "            for i, image_url in enumerate(image_urls):\n",
    "                image_response = requests.get(image_url)\n",
    "                if image_response.status_code == 200:\n",
    "                    # Sanitize filename\n",
    "                    safe_name = f\"{color}_{object_name}\".replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                    image_path = f\"downloaded_images/{safe_name}_{i+1}.jpg\"\n",
    "                    with open(image_path, \"wb\") as f:\n",
    "                        f.write(image_response.content)\n",
    "                    image_paths.append(image_path)\n",
    "        return image_urls, image_paths\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching images for {color} {object_name}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df[[\"image_url\", \"image_path\"]] = df.apply(\n",
    "    lambda row: pd.Series(fetch_and_download_images(row[\"Concept\"], row[\"Typical_Color\"])), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bfd37-bf63-4c30-a8a3-35992b7f6440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through the DataFrame and display each image\n",
    "for i, row in df.iterrows():\n",
    "    if row[\"image_path\"]:  # Check if there are image paths\n",
    "        for j, image_path in enumerate(row[\"image_path\"]):  # Iterate through all images\n",
    "            print(f\"Displaying: {image_path}\")  # Print file name\n",
    "\n",
    "            # Open and display the image\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                plt.figure()  # Create a new figure for each image\n",
    "                plt.imshow(image)\n",
    "                plt.axis(\"off\")  # Hide axes\n",
    "                #plt.title(f\"{row['correct_answer']} {row['correct_object']} - Image {j+1}\")  # Title with object, color, and number\n",
    "                plt.show()  # Show the image\n",
    "            except Exception as e:\n",
    "                print(f\"Error displaying {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10cd86-e75d-4528-b79c-538f7ecdcd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Expand the dataframe so each image has its own row\n",
    "\n",
    "# Explode the 'image_path' column while keeping other data duplicated\n",
    "df_expanded = df.explode(\"image_path\").reset_index(drop=True)\n",
    "\n",
    "# Create an empty column for the GPT API responses\n",
    "df_expanded[\"gpt_response\"] = None\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c891c4-9f6e-45c4-a1ef-f616fdd0b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the function to query the GPT API for each image\n",
    "\n",
    "import openai\n",
    "import base64\n",
    "\n",
    "def evaluate_image_with_gpt(image_path, object_name, color, model_version=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Queries the GPT API to analyze the image and answer specific questions.\n",
    "    \"\"\"\n",
    "    API_KEY = \"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\"\n",
    "    \n",
    "    client = openai.OpenAI(api_key=API_KEY)\n",
    "    \n",
    "    # Encode image to base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "    # Define the questions\n",
    "    questions = [\n",
    "        f\"1. Is this an image of a {color} {object_name}? Answer with 'yes' or 'no'.\",\n",
    "        \"2. Is this image on a white background? Answer with 'yes' or 'no'.\",\n",
    "        \"3. Is this image an illustration (cartoon, clipart, painting) or a realistic image? Answer with 'illustration' or 'realistic'.\",\n",
    "        f\"4. On a scale of 1 through 10, 1 being not realistic and 10 being realistic, how realistic is this {object_name}? Answer with the number.'\"\n",
    "    ]\n",
    "    \n",
    "    # Send request to GPT API\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_version,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the image and answer the following questions.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"\\n\".join(questions)},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        top_p=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb6d4d-d559-4bec-b680-6e6e5372fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4fa9d-fa03-40e0-90d5-6c5cfbea5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Loop through each row in the expanded dataframe and query GPT API\n",
    "\n",
    "for i, row in df_expanded.iterrows():\n",
    "    image_path = row[\"image_path\"]\n",
    "    object_name = row[\"Concept\"]\n",
    "    color = row[\"Typical_Color\"]  # Assuming the color is stored in this column\n",
    "    \n",
    "    try:\n",
    "        gpt_response = evaluate_image_with_gpt(image_path, object_name, color)\n",
    "        df_expanded.at[i, \"gpt_response\"] = gpt_response  # Store response in dataframe\n",
    "    except Exception as e:\n",
    "        df_expanded.at[i, \"gpt_response\"] = f\"Error: {e}\"  # Store error if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a225e9-1a83-418c-957b-2ef5775fb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded[\"gpt_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71877eb-cdfe-4bbe-88f8-fb78366e9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.to_csv(\"gpt_ranked_images.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01048c28-9381-4dec-b65d-5d32b5e0c6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777ff04-769b-4a99-b3c1-0e425f164e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_expanded  = pd.read_csv(\"gpt_ranked_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992ae3-a3bd-496e-a9d1-45da3a070f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to calculate score based on GPT response\n",
    "def calculate_score(response):\n",
    "    \"\"\"\n",
    "    Calculates the score based on the response format.\n",
    "    \"\"\"\n",
    "    if not isinstance(response, str):\n",
    "        return 0  # Handle cases where response is not a string\n",
    "\n",
    "    # Extract responses using regex\n",
    "    match = re.findall(r\"\\d+\\.\\s(Yes|No|Illustration|Realistic|\\d+)\", response)\n",
    "\n",
    "    if len(match) < 4:\n",
    "        return 0  # If responses are incomplete, return 0\n",
    "\n",
    "    # Extract individual responses\n",
    "    answer_1, answer_2, answer_3, answer_4 = match\n",
    "\n",
    "    # If answer to Q1 is \"No\", score is 0\n",
    "    if answer_1.lower() == \"no\":\n",
    "        return 0\n",
    "\n",
    "    # Otherwise, calculate the score\n",
    "    score = 0\n",
    "    if answer_2.lower() == \"yes\":\n",
    "        score += 10\n",
    "    if answer_3.lower() == \"realistic\":\n",
    "        score += 10\n",
    "    if answer_4.isdigit():\n",
    "        score += int(answer_4)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Apply scoring function to the GPT response column\n",
    "df_expanded[\"score\"] = df_expanded[\"gpt_response\"].apply(calculate_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0e043-3f81-42e8-8727-56d2b0634517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b96bb-39ae-41d7-8634-0e39a03b1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list columns into strings to make them hashable for grouping\n",
    "df_expanded_fixed = df_expanded.copy()\n",
    "\n",
    "for col in df_expanded_fixed.columns:\n",
    "    if df_expanded_fixed[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        df_expanded_fixed[col] = df_expanded_fixed[col].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Identify the columns to group by (excluding image_path, gpt_response, score)\n",
    "grouping_keys = df_expanded_fixed.columns.difference([\"image_path\", \"gpt_response\", \"score\"]).tolist()\n",
    "\n",
    "# Find the index of the row with the highest score for each group\n",
    "best_score_idx = df_expanded_fixed.groupby(grouping_keys)[\"score\"].idxmax()\n",
    "\n",
    "# Select only the best-scoring rows\n",
    "df_best_scores = df_expanded_fixed.loc[best_score_idx].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233eea8d-e419-445e-90c5-c9ccc34998a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both columns to lowercase for consistency\n",
    "objects = df[\"correct_object\"].str.lower().tolist()\n",
    "concepts = df_best_scores[\"Concept\"].str.lower().tolist()\n",
    "\n",
    "# Store any overlaps\n",
    "overlaps = []\n",
    "\n",
    "for obj in objects:\n",
    "    for concept in concepts:\n",
    "        if obj == concept:  # optional: skip exact matches\n",
    "            overlaps.append((obj, concept))\n",
    "\n",
    "# Convert to DataFrame to inspect\n",
    "overlap_df = pd.DataFrame(overlaps, columns=[\"correct_object\", \"Concept\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65a39e-1df0-43ce-936a-4110286076a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_scores = df_best_scores[~df_best_scores[\"Concept\"].isin(overlap_df[\"Concept\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633c6ca-5ef0-465d-8310-171ce3c38f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both columns to lowercase for consistency\n",
    "objects = df[\"correct_object\"].str.lower().tolist()\n",
    "concepts = df_best_scores[\"Concept\"].str.lower().tolist()\n",
    "\n",
    "# Store any overlaps\n",
    "overlaps = []\n",
    "\n",
    "for obj in objects:\n",
    "    for concept in concepts:\n",
    "        if obj in concept:  # optional: skip exact matches\n",
    "            overlaps.append((obj, concept))\n",
    "\n",
    "# Convert to DataFrame to inspect\n",
    "overlap_df = pd.DataFrame(overlaps, columns=[\"correct_object\", \"Concept\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1c50-678c-4d0c-b658-1f845657b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398cf92-d876-4d1e-9a6f-305411daa62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_df[overlap_df[\"Concept\"] == 'american lobster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c3c58-4e71-4447-9a81-274edbafb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['african elephant', 'indian elephant','american black bear', 'brown bear','ice bear','king penguin',\n",
    "            'bell pepper', 'grand piano','oak_tree', 'great grey owl', 'soup bowl','grey fox',\n",
    "       'red fox', 'keyboard', 'american alligator', 'common iguana', 'pine_tree', 'mud turtle', 'custard apple',\n",
    "            'american lobster', 'school bus', 'willow_tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33603af2-0f05-463c-8ca0-1b492f7dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee5428-caaa-4fe4-b0b3-d68dc0397861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_scores = df_best_scores[~df_best_scores[\"Concept\"].str.lower().isin(drop_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ca5d5-6bef-4359-b55b-2aa08005845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_scores = df_best_scores.drop_duplicates(\"Concept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00766f-3e52-447a-89b1-6a42057aa446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed  = df_best_scores[df_best_scores[\"score\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae82d07-308a-4f99-833e-11b2e5c7ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROUND TWO: for failed images, retry! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebcc53-0f69-4afb-a47a-6038914266b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a folder to store downloaded images\n",
    "os.makedirs(\"downloaded_images\", exist_ok=True)\n",
    "\n",
    "# Function to fetch image URLs and download multiple images\n",
    "def fetch_and_download_images(object_name, color, num_results=3):\n",
    "    QUERY = f\"a {object_name} on a white background\" #{color} \n",
    "    URL = f\"https://www.googleapis.com/customsearch/v1?q={QUERY}&cx={CX_ID}&key={API_KEY}&searchType=image&num={num_results}\"\n",
    "\n",
    "    image_urls = []\n",
    "    image_paths = []\n",
    "\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract image URLs\n",
    "        if \"items\" in data:\n",
    "            image_urls = [item[\"link\"] for item in data[\"items\"][:num_results]]  # Get first 'num_results' images\n",
    "            \n",
    "            # Download images\n",
    "            for i, image_url in enumerate(image_urls):\n",
    "                image_response = requests.get(image_url)\n",
    "                \n",
    "                if image_response.status_code == 200:\n",
    "                    image_path = f\"downloaded_images/{color}_{object_name}_{i+1}.jpg\"\n",
    "                    with open(image_path, \"wb\") as f:\n",
    "                        f.write(image_response.content)\n",
    "                    \n",
    "                    image_paths.append(image_path)  # Store the file path\n",
    "        return image_urls, image_paths  # Return both lists\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching images for {color} {object_name}: {e}\")\n",
    "        return [], []\n",
    "# Fetch image URLs and download images\n",
    "df_failed[[\"image_url\", \"image_path\"]] = df_failed.apply(\n",
    "    lambda row: pd.Series(fetch_and_download_images(row[\"Concept\"], row[\"Typical_Color\"])), axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c0696-dd11-4979-8a69-b895d8b0b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_failed = df_failed.explode(\"image_path\").reset_index(drop=True)\n",
    "\n",
    "# Create an empty column for the GPT API responses\n",
    "df_expanded_failed[\"gpt_response\"] = None\n",
    "\n",
    "df_expanded_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337513e0-e7ed-4d38-a460-b3da06064c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_expanded_failed.iterrows():\n",
    "    image_path = row[\"image_path\"]\n",
    "    object_name = row[\"Concept\"]\n",
    "    color = row[\"Typical_Color\"]  # Assuming the color is stored in this column\n",
    "    \n",
    "    try:\n",
    "        gpt_response = evaluate_image_with_gpt(image_path, object_name, color)\n",
    "        df_expanded_failed.at[i, \"gpt_response\"] = gpt_response  # Store response in dataframe\n",
    "    except Exception as e:\n",
    "        df_expanded_failed.at[i, \"gpt_response\"] = f\"Error: {e}\"  # Store error if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754bbd0-02e3-4d0d-bd9e-e1863f94b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_failed[\"score\"] = df_expanded_failed[\"gpt_response\"].apply(calculate_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ed192-efb5-4b73-bbd2-305bf72f6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_failed[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e9e68-0a67-40e6-a03b-64443388baf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through the DataFrame and display each image\n",
    "for i, row in df_expanded_failed.iterrows():\n",
    "    if row[\"image_path\"]:  # Check if there are image paths\n",
    "        #for j, image_path in enumerate(row[\"image_path\"]):  # Iterate through all images\n",
    "        image_path = row[\"image_path\"]\n",
    "        print(f\"Displaying: {image_path}\")  # Print file name\n",
    "        score = row[\"score\"]\n",
    "        print(f\"Score: {score}\")\n",
    "        # Open and display the image\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            plt.figure()  # Create a new figure for each image\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")  # Hide axes\n",
    "            #plt.title(f\"{row['correct_answer']} {row['correct_object']} - Image {j+1}\")  # Title with object, color, and number\n",
    "            plt.show()  # Show the image\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a83fed-8d87-405d-aa2b-60e917559816",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_expanded_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e19aa-10db-4583-af11-426475c090a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_failed = df_expanded_failed[df_expanded_failed[\"image_path\"] != \"downloaded_images/black_binoculars_1.jpg\"]\n",
    "df_expanded_failed = df_expanded_failed[df_expanded_failed[\"image_path\"] != \"downloaded_images/brown_espresso_2.jpg\"]\n",
    "df_expanded_failed = df_expanded_failed[df_expanded_failed[\"image_path\"] != \"downloaded_images/grey_vault_1.jpg\"]\n",
    "df_expanded_failed = df_expanded_failed[df_expanded_failed[\"image_path\"] != \"downloaded_images/brown_worm fence_3.jpg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db80d5-e42f-406f-9cb3-3eb61dd5c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list columns into strings to make them hashable for grouping\n",
    "df_expanded_failed = df_expanded_failed.copy()\n",
    "\n",
    "for col in df_expanded_failed.columns:\n",
    "    if df_expanded_failed[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        df_expanded_failed[col] = df_expanded_failed[col].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Identify the columns to group by (excluding image_path, gpt_response, score)\n",
    "grouping_keys = df_expanded_failed.columns.difference([\"image_path\", \"gpt_response\", \"score\"]).tolist()\n",
    "\n",
    "# Find the index of the row with the highest score for each group\n",
    "best_score_idx = df_expanded_failed.groupby(grouping_keys)[\"score\"].idxmax()\n",
    "\n",
    "# Select only the best-scoring rows\n",
    "df_best_scores_failed = df_expanded_failed.loc[best_score_idx].reset_index(drop=True)\n",
    "df_best_scores_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ec8b5-009e-4c60-940c-bba428e1b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_best_scores_failed[df_best_scores_failed[\"score\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42236a50-970c-4567-9ddd-708765469698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_best_scores[df_best_scores[\"score\"] != 0], df_best_scores_failed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f4555-0d7a-4d73-b3c4-3dbe0e848810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through the DataFrame and display each image\n",
    "for i, row in df_final.iterrows():\n",
    "    if row[\"image_path\"]:  # Check if there are image paths\n",
    "        #for j, image_path in enumerate(row[\"image_path\"]):  # Iterate through all images\n",
    "        image_path = row[\"image_path\"]\n",
    "        print(f\"Displaying: {image_path}\")  # Print file name\n",
    "        score = row[\"score\"]\n",
    "        print(f\"Score: {score}\")\n",
    "        # Open and display the image\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            plt.figure()  # Create a new figure for each image\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")  # Hide axes\n",
    "            #plt.title(f\"{row['correct_answer']} {row['correct_object']} - Image {j+1}\")  # Title with object, color, and number\n",
    "            plt.show()  # Show the image\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3134f-5e71-4e0b-9144-4b65cd473e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"correct_object\"] = df_final[\"Concept\"]\n",
    "df_final[\"correct_answer\"] = df_final[\"Typical_Color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932ab2d-86f2-4174-b32a-ed2605c0a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(set(df.columns).intersection(set(df_final.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc521cbc-e9ce-41d0-87ff-73ca2c844462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define thresholds\n",
    "black_threshold = 30  # RGB values ≤ 30 are considered black\n",
    "black_ratio_threshold = 0.7  # 90% of the last row must be black\n",
    "blue_color = (14, 119, 176)  # The specific blue color to detect\n",
    "blue_tolerance = 30  # Allow some variation in blue detection\n",
    "blue_ratio_threshold = 0.7  # 90% of the last row must be blue\n",
    "\n",
    "# List to store images with black or blue in the last row\n",
    "valid_images = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row.get(\"image_path\")\n",
    "    \n",
    "    if not image_path:\n",
    "        continue  # Skip if no image path is provided\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Get the last row of pixels\n",
    "        last_row = image_array[-1, :, :]\n",
    "\n",
    "        # Detect black pixels\n",
    "        black_pixels = np.sum(np.all(last_row <= black_threshold, axis=1))\n",
    "\n",
    "        # Detect blue pixels (within tolerance range)\n",
    "        blue_pixels = np.sum(\n",
    "            (np.abs(last_row[:, 0] - blue_color[0]) <= blue_tolerance) &\n",
    "            (np.abs(last_row[:, 1] - blue_color[1]) <= blue_tolerance) &\n",
    "            (np.abs(last_row[:, 2] - blue_color[2]) <= blue_tolerance)\n",
    "        )\n",
    "\n",
    "        total_pixels = last_row.shape[0]\n",
    "\n",
    "        # Check if at least 90% of the last row is black or blue\n",
    "        if (black_pixels / total_pixels >= black_ratio_threshold) or (blue_pixels / total_pixels >= blue_ratio_threshold):\n",
    "            valid_images.append((image_path, image))  # Store path and image object\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# Display valid images\n",
    "if valid_images:\n",
    "    for _, img in valid_images:\n",
    "        display(img)\n",
    "else:\n",
    "    print(\"No images found with 90% black or blue pixels in the last row.\")\n",
    "\n",
    "# List to store cropped images with their paths\n",
    "cropped_images = []\n",
    "\n",
    "for image_path, image in valid_images:\n",
    "    try:\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # Identify rows that are mostly black (90% of pixels or more)\n",
    "        black_rows = np.sum(np.all(image_array <= black_threshold, axis=2), axis=1) / image_array.shape[1] >= black_ratio_threshold\n",
    "\n",
    "        # Identify rows that are mostly blue (90% of pixels within tolerance)\n",
    "        blue_rows = np.sum(\n",
    "            (np.abs(image_array[:, :, 0] - blue_color[0]) <= blue_tolerance) &\n",
    "            (np.abs(image_array[:, :, 1] - blue_color[1]) <= blue_tolerance) &\n",
    "            (np.abs(image_array[:, :, 2] - blue_color[2]) <= blue_tolerance),\n",
    "            axis=1\n",
    "        ) / image_array.shape[1] >= blue_ratio_threshold\n",
    "\n",
    "        # Iterate from the bottom up to find the first non-black or non-blue row\n",
    "        crop_end = image_array.shape[0]  # Default to full image height\n",
    "\n",
    "        for i in range(image_array.shape[0] - 1, -1, -1):\n",
    "            if black_rows[i]:  # If it's a black row, continue moving up\n",
    "                continue\n",
    "            elif blue_rows[i]:  # If it's a blue row, continue moving up\n",
    "                continue\n",
    "            else:\n",
    "                crop_end = i + 1  # Stop cropping here\n",
    "                break\n",
    "\n",
    "        # Ensure we don't crop the entire image to zero height\n",
    "        if crop_end <= 0:\n",
    "            print(f\"Skipping {image_path} to avoid empty image.\")\n",
    "            cropped_images.append((image_path, image))\n",
    "            continue\n",
    "\n",
    "        # Crop the image from the top to the last valid row\n",
    "        cropped_image = image.crop((0, 0, image.width, crop_end))\n",
    "\n",
    "        cropped_images.append((image_path, cropped_image))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af3d1f-7ee4-40ee-9fcf-de185afd875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cropped images\n",
    "if cropped_images:\n",
    "    for _, img in cropped_images:\n",
    "        display(img)\n",
    "else:\n",
    "    print(\"No images were cropped.\")\n",
    "\n",
    "# Save cropped images back to their original paths**\n",
    "for image_path, cropped_image in cropped_images:\n",
    "    try:\n",
    "        cropped_image.save(image_path)\n",
    "        print(f\"Saved cropped image to {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving cropped image {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e30b0-cd3c-4646-827a-d2eedb65932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"final_images.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
